{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "acd02fa3",
   "metadata": {},
   "source": [
    "# Uday Srivastava - Hrytos - AI Intern Assessment\n",
    "# Singapore Public Transport Query Agent (Take-Home Assessment)\n",
    "\n",
    "This notebook covers both assignment parts:\n",
    "- **Part 1:** Agentic workflow for Singapore transport queries using live APIs.\n",
    "- **Part 2:** Simulation of **10 users** with captured responses.\n",
    "\n",
    "Focus is on engineering approach, workflow structure, and documentation quality.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ffaadcf",
   "metadata": {},
   "source": [
    "## Approach and Thought Process\n",
    "\n",
    "### Design intent\n",
    "The solution is **tool-first** (API-grounded) rather than LLM-only. This improves reliability, traceability, and debuggability.\n",
    "\n",
    "### Workflow stages\n",
    "1. `parse_query` -> extract intent/entities from user text\n",
    "2. `enrich_context` -> add weather, traffic, time-of-day, holiday/event context\n",
    "3. `run_transport_tool` -> call relevant transport tools (bus/traffic/taxi)\n",
    "4. `compose_response` -> deterministic response, optional Groq refinement\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee4ff4cb",
   "metadata": {},
   "source": [
    "## Evaluation Criteria Mapping\n",
    "\n",
    "1. **Agentic workflow design**: explicit node-based pipeline with tool routing.\n",
    "2. **Input variety and constraints**: simulation includes weather, traffic, time-of-day, holidays, events.\n",
    "3. **Solution structure**: clear sectioning from setup -> tools -> workflow -> simulation -> deployment.\n",
    "4. **Clarity and documentation**: concise inline explanations and rationale.\n",
    "5. **Deployment understanding**: practical production architecture and operations notes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113d3bda-abc3-4840-9198-195893d363e7",
   "metadata": {},
   "source": [
    "## README\n",
    "\n",
    "### Setup\n",
    "1. Create and activate a local virtual environment.\n",
    "2. Set environment variables:\n",
    "   - `LTA_ACCOUNT_KEY`\n",
    "   - `GROQ_API_KEY`\n",
    "3. Open the notebook and run all cells top-to-bottom.\n",
    "\n",
    "### Expected output\n",
    "- Part 1 cells show successful agent workflow execution.\n",
    "- Part 2 displays a styled table with exactly 10 user simulations and responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07d3ca39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete. Time now (SG): 2026-02-23T03:52:42+08:00\n"
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "from functools import lru_cache\n",
    "from html import escape\n",
    "from typing import Any, TypedDict, Literal\n",
    "from zoneinfo import ZoneInfo\n",
    "\n",
    "import requests\n",
    "\n",
    "try:\n",
    "    from IPython.display import HTML, Markdown, display\n",
    "except Exception:\n",
    "    HTML = None\n",
    "    Markdown = None\n",
    "\n",
    "    def display(obj):\n",
    "        print(obj)\n",
    "\n",
    "SG_TZ = ZoneInfo(\"Asia/Singapore\")\n",
    "\n",
    "\n",
    "def now_sg() -> datetime:\n",
    "    return datetime.now(SG_TZ)\n",
    "\n",
    "\n",
    "print(\"Setup complete. Time now (SG):\", now_sg().isoformat(timespec=\"seconds\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36ee8dd",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "Environment variables:\n",
    "- `LTA_ACCOUNT_KEY` for live LTA DataMall access\n",
    "- `GROQ_API_KEY` for optional response refinement\n",
    "- `GROQ_MODEL` (default: `llama-3.1-8b-instant`)\n",
    "- `GROQ_CALL_BUDGET` (default: `6`, set `-1` for unlimited)\n",
    "\n",
    "If API keys or network fail, deterministic mock fallback keeps the notebook runnable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26af41ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LTA key configured: True\n",
      "Groq key configured: True\n",
      "Groq synthesis enabled: True\n",
      "Groq call budget: 6\n",
      "Mock fallback enabled: True\n"
     ]
    }
   ],
   "source": [
    "LTA_ACCOUNT_KEY = os.getenv(\"LTA_ACCOUNT_KEY\", \"\").strip()\n",
    "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\", \"\").strip()\n",
    "GROQ_MODEL = os.getenv(\"GROQ_MODEL\", \"llama-3.1-8b-instant\").strip()\n",
    "\n",
    "USE_MOCK_IF_UNAVAILABLE = True\n",
    "USE_GROQ_SYNTHESIS = bool(GROQ_API_KEY)\n",
    "SHOW_LLM_ERRORS = False\n",
    "\n",
    "GROQ_CALL_BUDGET = int(os.getenv(\"GROQ_CALL_BUDGET\", \"6\"))\n",
    "GROQ_CALL_COUNT = 0\n",
    "\n",
    "HTTP_TIMEOUT_SECONDS = 8\n",
    "\n",
    "LTA_BASE = \"https://datamall2.mytransport.sg/ltaodataservice\"\n",
    "OPEN_METEO_URL = \"https://api.open-meteo.com/v1/forecast\"\n",
    "NAGER_HOLIDAY_URL = \"https://date.nager.at/api/v3/PublicHolidays\"\n",
    "GROQ_URL = \"https://api.groq.com/openai/v1/chat/completions\"\n",
    "\n",
    "print(\"LTA key configured:\", bool(LTA_ACCOUNT_KEY))\n",
    "print(\"Groq key configured:\", bool(GROQ_API_KEY))\n",
    "print(\"Groq synthesis enabled:\", USE_GROQ_SYNTHESIS)\n",
    "print(\"Groq call budget:\", GROQ_CALL_BUDGET)\n",
    "print(\"Mock fallback enabled:\", USE_MOCK_IF_UNAVAILABLE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cdf19dc",
   "metadata": {},
   "source": [
    "## Step 1 - API Tool Layer\n",
    "\n",
    "Engineering choices:\n",
    "- retries + timeout for resilience\n",
    "- lightweight caching for efficiency\n",
    "- explicit source labels for traceability\n",
    "- deterministic fallback for reproducibility\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f9752ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool layer loaded.\n"
     ]
    }
   ],
   "source": [
    "def _headers_for_lta() -> dict[str, str]:\n",
    "    if not LTA_ACCOUNT_KEY:\n",
    "        return {\"accept\": \"application/json\"}\n",
    "    return {\"AccountKey\": LTA_ACCOUNT_KEY, \"accept\": \"application/json\"}\n",
    "\n",
    "\n",
    "def _http_request_json(\n",
    "    method: str,\n",
    "    url: str,\n",
    "    params: dict[str, Any] | None = None,\n",
    "    headers: dict[str, str] | None = None,\n",
    "    json_body: dict[str, Any] | None = None,\n",
    "    retries: int = 2,\n",
    "    timeout: int = HTTP_TIMEOUT_SECONDS,\n",
    ") -> tuple[dict[str, Any] | list[Any] | None, str | None]:\n",
    "    last_error: str | None = None\n",
    "    for attempt in range(retries + 1):\n",
    "        try:\n",
    "            response = requests.request(\n",
    "                method=method,\n",
    "                url=url,\n",
    "                params=params,\n",
    "                headers=headers,\n",
    "                json=json_body,\n",
    "                timeout=timeout,\n",
    "            )\n",
    "            if response.status_code == 200:\n",
    "                return response.json(), None\n",
    "            last_error = f\"HTTP {response.status_code}: {response.text[:180]}\"\n",
    "        except Exception as exc:\n",
    "            last_error = f\"{type(exc).__name__}: {exc}\"\n",
    "        if attempt < retries:\n",
    "            time.sleep(0.5 * (2**attempt))\n",
    "    return None, (last_error or \"Unknown HTTP error\")\n",
    "\n",
    "\n",
    "def _http_get_json(url: str, params: dict[str, Any] | None = None, headers: dict[str, str] | None = None, retries: int = 2):\n",
    "    return _http_request_json(\"GET\", url, params=params, headers=headers, retries=retries)\n",
    "\n",
    "\n",
    "def _http_post_json(url: str, headers: dict[str, str] | None = None, json_body: dict[str, Any] | None = None, retries: int = 2):\n",
    "    return _http_request_json(\"POST\", url, headers=headers, json_body=json_body, retries=retries)\n",
    "\n",
    "\n",
    "def _iso_in_minutes(minutes: int) -> str:\n",
    "    return (now_sg() + timedelta(minutes=minutes)).isoformat()\n",
    "\n",
    "\n",
    "def _time_bucket(minutes: int = 5) -> str:\n",
    "    n = now_sg()\n",
    "    floored = n.replace(minute=(n.minute // minutes) * minutes, second=0, microsecond=0)\n",
    "    return floored.isoformat(timespec=\"minutes\")\n",
    "\n",
    "\n",
    "def _mock_bus_arrival(stop_code: str, service_no: str | None = None, error: str | None = None) -> dict[str, Any]:\n",
    "    base = [\n",
    "        {\"ServiceNo\": \"14\", \"NextBus\": {\"EstimatedArrival\": _iso_in_minutes(3), \"Load\": \"SDA\", \"Feature\": \"WAB\"}, \"NextBus2\": {\"EstimatedArrival\": _iso_in_minutes(9)}},\n",
    "        {\"ServiceNo\": \"67\", \"NextBus\": {\"EstimatedArrival\": _iso_in_minutes(6), \"Load\": \"SEA\", \"Feature\": \"WAB\"}, \"NextBus2\": {\"EstimatedArrival\": _iso_in_minutes(12)}},\n",
    "        {\"ServiceNo\": \"190\", \"NextBus\": {\"EstimatedArrival\": _iso_in_minutes(2), \"Load\": \"LSD\", \"Feature\": \"\"}, \"NextBus2\": {\"EstimatedArrival\": _iso_in_minutes(8)}},\n",
    "    ]\n",
    "    if service_no:\n",
    "        base = [s for s in base if s[\"ServiceNo\"] == service_no]\n",
    "    return {\"source\": \"mock\", \"bus_stop_code\": stop_code, \"services\": base, \"warning\": f\"Using mock bus data ({error})\" if error else \"Using mock bus data (no LTA key)\"}\n",
    "\n",
    "\n",
    "def _mock_traffic(error: str | None = None) -> dict[str, Any]:\n",
    "    incidents = [\n",
    "        {\"Type\": \"Accident\", \"Message\": \"Accident on PIE (towards Tuas) near Clementi Ave 6\"},\n",
    "        {\"Type\": \"Road Works\", \"Message\": \"Road works on CTE (towards SLE) after Ang Mo Kio Ave 1\"},\n",
    "    ]\n",
    "    return {\"source\": \"mock\", \"incident_count\": len(incidents), \"incidents\": incidents, \"warning\": f\"Using mock traffic data ({error})\" if error else \"Using mock traffic data\"}\n",
    "\n",
    "\n",
    "def _mock_taxi(error: str | None = None) -> dict[str, Any]:\n",
    "    return {\"source\": \"mock\", \"taxi_count\": 2480, \"warning\": f\"Using mock taxi data ({error})\" if error else \"Using mock taxi data\"}\n",
    "\n",
    "\n",
    "def _mock_weather(error: str | None = None) -> dict[str, Any]:\n",
    "    return {\"source\": \"mock\", \"temperature_c\": 30.2, \"rain_mm\": 0.6, \"precip_probability\": 70, \"warning\": f\"Using mock weather data ({error})\" if error else \"Using mock weather data\"}\n",
    "\n",
    "\n",
    "def _mock_holidays(year: int) -> dict[str, str]:\n",
    "    return {f\"{year}-01-01\": \"New Year's Day\", f\"{year}-05-01\": \"Labour Day\", f\"{year}-08-09\": \"National Day\", f\"{year}-12-25\": \"Christmas Day\"}\n",
    "\n",
    "\n",
    "def _eta_minutes(iso_value: str | None) -> int | None:\n",
    "    if not iso_value:\n",
    "        return None\n",
    "    try:\n",
    "        dt = datetime.fromisoformat(iso_value.replace(\"Z\", \"+00:00\")).astimezone(SG_TZ)\n",
    "        return max(0, int(round((dt - now_sg()).total_seconds() / 60)))\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "\n",
    "@lru_cache(maxsize=32)\n",
    "def fetch_bus_arrival_cached(stop_code: str, service_no: str | None, bucket: str) -> dict[str, Any]:\n",
    "    if not LTA_ACCOUNT_KEY and USE_MOCK_IF_UNAVAILABLE:\n",
    "        return _mock_bus_arrival(stop_code, service_no)\n",
    "\n",
    "    params = {\"BusStopCode\": stop_code, **({\"ServiceNo\": service_no} if service_no else {})}\n",
    "    payload, error = _http_get_json(\n",
    "        f\"{LTA_BASE}/v3/BusArrival\",\n",
    "        params=params,\n",
    "        headers=_headers_for_lta(),\n",
    "    )\n",
    "\n",
    "    if payload is None:\n",
    "        return _mock_bus_arrival(stop_code, service_no, error) if USE_MOCK_IF_UNAVAILABLE else {\"source\": \"error\", \"error\": error}\n",
    "\n",
    "    services = payload.get(\"Services\", []) if isinstance(payload, dict) else []\n",
    "    return {\"source\": \"lta\", \"bus_stop_code\": stop_code, \"services\": services, \"warning\": None}\n",
    "\n",
    "\n",
    "def fetch_bus_arrival(stop_code: str, service_no: str | None = None) -> dict[str, Any]:\n",
    "    return fetch_bus_arrival_cached(stop_code, service_no, _time_bucket(1))\n",
    "\n",
    "\n",
    "@lru_cache(maxsize=16)\n",
    "def fetch_traffic_incidents_cached(bucket: str) -> dict[str, Any]:\n",
    "    if not LTA_ACCOUNT_KEY and USE_MOCK_IF_UNAVAILABLE:\n",
    "        return _mock_traffic()\n",
    "    payload, error = _http_get_json(f\"{LTA_BASE}/TrafficIncidents\", headers=_headers_for_lta())\n",
    "    if payload is None:\n",
    "        return _mock_traffic(error) if USE_MOCK_IF_UNAVAILABLE else {\"source\": \"error\", \"incident_count\": 0, \"incidents\": [], \"warning\": error}\n",
    "    incidents = payload.get(\"value\", []) if isinstance(payload, dict) else []\n",
    "    return {\"source\": \"lta\", \"incident_count\": len(incidents), \"incidents\": incidents[:5], \"warning\": None}\n",
    "\n",
    "\n",
    "def fetch_traffic_incidents() -> dict[str, Any]:\n",
    "    return fetch_traffic_incidents_cached(_time_bucket(5))\n",
    "\n",
    "\n",
    "@lru_cache(maxsize=16)\n",
    "def fetch_taxi_availability_cached(bucket: str) -> dict[str, Any]:\n",
    "    if not LTA_ACCOUNT_KEY and USE_MOCK_IF_UNAVAILABLE:\n",
    "        return _mock_taxi()\n",
    "    payload, error = _http_get_json(f\"{LTA_BASE}/Taxi-Availability\", headers=_headers_for_lta())\n",
    "    if payload is None:\n",
    "        return _mock_taxi(error) if USE_MOCK_IF_UNAVAILABLE else {\"source\": \"error\", \"taxi_count\": None, \"warning\": error}\n",
    "    coords = payload.get(\"value\", []) if isinstance(payload, dict) else []\n",
    "    return {\"source\": \"lta\", \"taxi_count\": len(coords), \"warning\": None}\n",
    "\n",
    "\n",
    "def fetch_taxi_availability() -> dict[str, Any]:\n",
    "    return fetch_taxi_availability_cached(_time_bucket(5))\n",
    "\n",
    "\n",
    "@lru_cache(maxsize=12)\n",
    "def fetch_weather_now_cached(bucket: str) -> dict[str, Any]:\n",
    "    payload, error = _http_get_json(\n",
    "        OPEN_METEO_URL,\n",
    "        params={\n",
    "            \"latitude\": 1.3521,\n",
    "            \"longitude\": 103.8198,\n",
    "            \"timezone\": \"Asia/Singapore\",\n",
    "            \"current\": \"temperature_2m,rain,precipitation\",\n",
    "            \"hourly\": \"precipitation_probability\",\n",
    "            \"forecast_days\": 1,\n",
    "        },\n",
    "        headers={\"accept\": \"application/json\"},\n",
    "    )\n",
    "    if payload is None:\n",
    "        return _mock_weather(error) if USE_MOCK_IF_UNAVAILABLE else {\"source\": \"error\", \"warning\": error}\n",
    "\n",
    "    current = payload.get(\"current\", {}) if isinstance(payload, dict) else {}\n",
    "    hourly = payload.get(\"hourly\", {}) if isinstance(payload, dict) else {}\n",
    "    now_hour_key = now_sg().strftime(\"%Y-%m-%dT%H:00\")\n",
    "    times = hourly.get(\"time\", [])\n",
    "    probs = hourly.get(\"precipitation_probability\", [])\n",
    "    precip_prob = probs[times.index(now_hour_key)] if now_hour_key in times and times.index(now_hour_key) < len(probs) else None\n",
    "\n",
    "    return {\"source\": \"open-meteo\", \"temperature_c\": current.get(\"temperature_2m\"), \"rain_mm\": current.get(\"rain\"), \"precip_probability\": precip_prob, \"warning\": None}\n",
    "\n",
    "\n",
    "def fetch_weather_now() -> dict[str, Any]:\n",
    "    return fetch_weather_now_cached(_time_bucket(30))\n",
    "\n",
    "\n",
    "@lru_cache(maxsize=4)\n",
    "def fetch_public_holidays_cached(year: int) -> dict[str, str]:\n",
    "    payload, error = _http_get_json(f\"{NAGER_HOLIDAY_URL}/{year}/SG\", headers={\"accept\": \"application/json\"})\n",
    "    if payload is None:\n",
    "        return _mock_holidays(year) if USE_MOCK_IF_UNAVAILABLE else {}\n",
    "    if not isinstance(payload, list):\n",
    "        return _mock_holidays(year)\n",
    "    out = {}\n",
    "    for item in payload:\n",
    "        if isinstance(item, dict) and item.get(\"date\") and item.get(\"localName\"):\n",
    "            out[str(item[\"date\"])] = str(item[\"localName\"])\n",
    "    return out\n",
    "\n",
    "\n",
    "def fetch_public_holidays(year: int | None = None) -> dict[str, str]:\n",
    "    return fetch_public_holidays_cached(year or now_sg().year)\n",
    "\n",
    "\n",
    "def _consume_groq_budget() -> tuple[bool, str | None]:\n",
    "    global GROQ_CALL_COUNT\n",
    "    if GROQ_CALL_BUDGET >= 0 and GROQ_CALL_COUNT >= GROQ_CALL_BUDGET:\n",
    "        return False, \"Groq call budget reached\"\n",
    "    GROQ_CALL_COUNT += 1\n",
    "    return True, None\n",
    "\n",
    "\n",
    "def call_groq_chat(prompt: str) -> tuple[str | None, str | None]:\n",
    "    if not USE_GROQ_SYNTHESIS or not GROQ_API_KEY:\n",
    "        return None, \"Groq disabled or key missing\"\n",
    "\n",
    "    ok, err = _consume_groq_budget()\n",
    "    if not ok:\n",
    "        return None, err\n",
    "\n",
    "    payload, error = _http_post_json(\n",
    "        GROQ_URL,\n",
    "        headers={\"Authorization\": f\"Bearer {GROQ_API_KEY}\", \"Content-Type\": \"application/json\"},\n",
    "        json_body={\n",
    "            \"model\": GROQ_MODEL,\n",
    "            \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "            \"temperature\": 0.2,\n",
    "            \"max_tokens\": 220,\n",
    "        },\n",
    "    )\n",
    "    if payload is None:\n",
    "        return None, error\n",
    "\n",
    "    try:\n",
    "        return payload[\"choices\"][0][\"message\"][\"content\"].strip(), None\n",
    "    except Exception as exc:\n",
    "        return None, f\"Groq parse error: {exc}\"\n",
    "\n",
    "\n",
    "print(\"Tool layer loaded.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403e2351",
   "metadata": {},
   "source": [
    "## Step 2 - Agent Workflow (LangGraph + Fallback)\n",
    "\n",
    "The workflow generates a grounded deterministic answer first, then optionally refines language with Groq.\n",
    "This keeps behavior stable under rate limits or provider downtime.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e32ff28e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent runner mode: langgraph\n"
     ]
    }
   ],
   "source": [
    "class AgentState(TypedDict, total=False):\n",
    "    user_query: str\n",
    "    intent: Literal[\"bus_arrival\", \"traffic\", \"taxi\", \"general\"]\n",
    "    entities: dict[str, Any]\n",
    "    context: dict[str, Any]\n",
    "    tool_result: dict[str, Any]\n",
    "    response: str\n",
    "    model_used: str\n",
    "    steps: list[str]\n",
    "\n",
    "\n",
    "BUS_STOP_RE = re.compile(r\"\\b(\\d{5})\\b\")\n",
    "SERVICE_RE = re.compile(r\"(?:service|svc)\\s*([A-Za-z0-9]+)\", re.IGNORECASE)\n",
    "\n",
    "\n",
    "def parse_query(state: AgentState) -> AgentState:\n",
    "    q = state[\"user_query\"].strip()\n",
    "    ql = q.lower()\n",
    "    stop_match = BUS_STOP_RE.search(q)\n",
    "    service_match = SERVICE_RE.search(q)\n",
    "\n",
    "    mentions_holiday = any(k in ql for k in [\"holiday\", \"public holiday\"])\n",
    "    mentions_weather = any(k in ql for k in [\"weather\", \"rain\", \"storm\"])\n",
    "\n",
    "    if any(k in ql for k in [\"taxi\", \"cab\"]):\n",
    "        intent: Literal[\"bus_arrival\", \"traffic\", \"taxi\", \"general\"] = \"taxi\"\n",
    "    elif any(k in ql for k in [\"traffic\", \"accident\", \"incident\", \"jam\", \"congestion\"]):\n",
    "        intent = \"traffic\"\n",
    "    elif mentions_holiday and not stop_match and not service_match:\n",
    "        intent = \"general\"\n",
    "    elif any(k in ql for k in [\"bus\", \"arrival\", \"next\"]) or (stop_match is not None):\n",
    "        intent = \"bus_arrival\"\n",
    "    elif mentions_weather:\n",
    "        intent = \"general\"\n",
    "    else:\n",
    "        intent = \"general\"\n",
    "\n",
    "    state[\"intent\"] = intent\n",
    "    state[\"entities\"] = {\n",
    "        \"bus_stop_code\": stop_match.group(1) if stop_match else None,\n",
    "        \"service_no\": service_match.group(1) if service_match else None,\n",
    "        \"mentions_weather\": mentions_weather,\n",
    "        \"mentions_holiday\": mentions_holiday,\n",
    "        \"mentions_event\": any(k in ql for k in [\"national day\", \"f1\", \"marathon\", \"event\"]),\n",
    "    }\n",
    "    state.setdefault(\"steps\", []).append(\"parse_query\")\n",
    "    return state\n",
    "\n",
    "\n",
    "def enrich_context(state: AgentState) -> AgentState:\n",
    "    now = now_sg()\n",
    "    holidays = fetch_public_holidays(now.year)\n",
    "    traffic = fetch_traffic_incidents()\n",
    "    weather = fetch_weather_now()\n",
    "\n",
    "    is_peak = now.weekday() < 5 and ((7 <= now.hour < 10) or (17 <= now.hour < 20))\n",
    "    today_key = now.date().isoformat()\n",
    "    ql = state[\"user_query\"].lower()\n",
    "\n",
    "    event_note = None\n",
    "    if \"national day\" in ql:\n",
    "        event_note = \"National Day-related crowds may increase waiting time in city areas.\"\n",
    "    elif \"f1\" in ql:\n",
    "        event_note = \"F1 event windows may trigger road diversions and heavy crowding.\"\n",
    "    elif \"marathon\" in ql:\n",
    "        event_note = \"Marathon road closures can affect buses near race routes.\"\n",
    "\n",
    "    state[\"context\"] = {\n",
    "        \"timestamp_sg\": now.isoformat(timespec=\"seconds\"),\n",
    "        \"time_of_day\": \"peak\" if is_peak else \"off_peak\",\n",
    "        \"is_public_holiday\": today_key in holidays,\n",
    "        \"holiday_name\": holidays.get(today_key),\n",
    "        \"weather\": weather,\n",
    "        \"traffic_snapshot\": {\n",
    "            \"incident_count\": traffic.get(\"incident_count\", 0),\n",
    "            \"top_incident\": (traffic.get(\"incidents\") or [{}])[0].get(\"Message\"),\n",
    "        },\n",
    "        \"event_note\": event_note,\n",
    "    }\n",
    "    state.setdefault(\"steps\", []).append(\"enrich_context\")\n",
    "    return state\n",
    "\n",
    "\n",
    "def run_transport_tool(state: AgentState) -> AgentState:\n",
    "    intent = state.get(\"intent\", \"general\")\n",
    "    entities = state.get(\"entities\", {})\n",
    "    if intent == \"bus_arrival\":\n",
    "        stop_code = entities.get(\"bus_stop_code\")\n",
    "        if not stop_code:\n",
    "            state[\"tool_result\"] = {\n",
    "                \"source\": \"none\",\n",
    "                \"error\": \"Bus stop code missing. Please include a 5-digit Singapore bus stop code.\",\n",
    "            }\n",
    "        else:\n",
    "            state[\"tool_result\"] = fetch_bus_arrival(\n",
    "                stop_code=stop_code,\n",
    "                service_no=entities.get(\"service_no\"),\n",
    "            )\n",
    "    elif intent == \"traffic\":\n",
    "        state[\"tool_result\"] = fetch_traffic_incidents()\n",
    "    elif intent == \"taxi\":\n",
    "        state[\"tool_result\"] = fetch_taxi_availability()\n",
    "    else:\n",
    "        state[\"tool_result\"] = {\n",
    "            \"source\": \"multi\",\n",
    "            \"weather\": fetch_weather_now(),\n",
    "            \"traffic\": fetch_traffic_incidents(),\n",
    "            \"taxi\": fetch_taxi_availability(),\n",
    "        }\n",
    "\n",
    "    state.setdefault(\"steps\", []).append(\"run_transport_tool\")\n",
    "    return state\n",
    "\n",
    "\n",
    "def _advisory_lines(context: dict[str, Any]) -> list[str]:\n",
    "    out: list[str] = []\n",
    "    weather = context.get(\"weather\", {})\n",
    "    traffic = context.get(\"traffic_snapshot\", {})\n",
    "\n",
    "    if (weather.get(\"precip_probability\") or 0) >= 60:\n",
    "        out.append(\"High rain probability: add 5-10 minute buffer.\")\n",
    "    if (traffic.get(\"incident_count\") or 0) > 0:\n",
    "        out.append(\"Live traffic incidents detected: expect mild schedule variability.\")\n",
    "    if context.get(\"time_of_day\") == \"peak\":\n",
    "        out.append(\"Peak-hour demand is active: expect fuller buses.\")\n",
    "    if context.get(\"is_public_holiday\"):\n",
    "        out.append(\n",
    "            f\"Today is {context.get('holiday_name') or 'Public holiday'}: commuter patterns can differ from weekdays.\"\n",
    "        )\n",
    "    if context.get(\"event_note\"):\n",
    "        out.append(context[\"event_note\"])\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def _build_deterministic_response(state: AgentState) -> str:\n",
    "    intent = state.get(\"intent\", \"general\")\n",
    "    context = state.get(\"context\", {})\n",
    "    result = state.get(\"tool_result\", {})\n",
    "\n",
    "    lines: list[str] = []\n",
    "\n",
    "    if intent == \"bus_arrival\":\n",
    "        if result.get(\"error\"):\n",
    "            lines.append(result[\"error\"])\n",
    "        else:\n",
    "            lines.append(f\"Bus arrival update for stop {result.get('bus_stop_code')}:\")\n",
    "            lines.append(f\"Data source: {result.get('source', 'unknown')}\")\n",
    "            services = result.get(\"services\", [])\n",
    "\n",
    "            if not services:\n",
    "                if 0 <= now_sg().hour < 5:\n",
    "                    lines.append(\"No live arrivals now. This may be due to late-night service gaps at this stop.\")\n",
    "                else:\n",
    "                    lines.append(\"No live arrivals returned for this stop/service at the moment.\")\n",
    "                tx = fetch_taxi_availability().get(\"taxi_count\")\n",
    "                if tx is not None:\n",
    "                    lines.append(f\"Fallback option: around {tx} taxis are available in the latest snapshot.\")\n",
    "            else:\n",
    "                load_map = {\n",
    "                    \"SEA\": \"Seats Available\",\n",
    "                    \"SDA\": \"Standing Available\",\n",
    "                    \"LSD\": \"Limited Standing\",\n",
    "                }\n",
    "                for svc in services[:3]:\n",
    "                    next_bus = svc.get(\"NextBus\") or {}\n",
    "                    eta1 = _eta_minutes(next_bus.get(\"EstimatedArrival\"))\n",
    "                    eta2 = _eta_minutes((svc.get(\"NextBus2\") or {}).get(\"EstimatedArrival\"))\n",
    "                    load = load_map.get(next_bus.get(\"Load\"), \"N/A\")\n",
    "                    feature = \"Wheelchair Accessible\" if next_bus.get(\"Feature\") == \"WAB\" else \"Standard\"\n",
    "                    lines.append(\n",
    "                        f\"- Service {svc.get('ServiceNo', '?')}: next {eta1 if eta1 is not None else 'N/A'} min, \"\n",
    "                        f\"following {eta2 if eta2 is not None else 'N/A'} min, load {load}, feature {feature}\"\n",
    "                    )\n",
    "\n",
    "            if result.get(\"warning\"):\n",
    "                lines.append(f\"Note: {result['warning']}\")\n",
    "\n",
    "    elif intent == \"traffic\":\n",
    "        lines.append(f\"Traffic snapshot: {result.get('incident_count', 0)} active incidents in feed.\")\n",
    "        lines.append(f\"Data source: {result.get('source', 'unknown')}\")\n",
    "        first = (result.get(\"incidents\") or [{}])[0].get(\"Message\")\n",
    "        if first:\n",
    "            lines.append(f\"Top incident: {first}\")\n",
    "\n",
    "    elif intent == \"taxi\":\n",
    "        lines.append(f\"Data source: {result.get('source', 'unknown')}\")\n",
    "        taxis = result.get(\"taxi_count\")\n",
    "        lines.append(f\"Taxi availability snapshot: ~{taxis if taxis is not None else 'N/A'} taxis reported.\")\n",
    "\n",
    "    else:\n",
    "        w = (result.get(\"weather\") or {}).get(\"precip_probability\")\n",
    "        t = (result.get(\"traffic\") or {}).get(\"incident_count\")\n",
    "        x = (result.get(\"taxi\") or {}).get(\"taxi_count\")\n",
    "        lines.append(\"Data sources: weather/open-meteo, traffic/lta, taxi/lta\")\n",
    "        lines.append(\"General commute planning summary:\")\n",
    "        lines.append(f\"- Rain probability: {w if w is not None else 'N/A'}%\")\n",
    "        lines.append(f\"- Traffic incidents: {t if t is not None else 'N/A'}\")\n",
    "        lines.append(f\"- Taxi count snapshot: {x if x is not None else 'N/A'}\")\n",
    "\n",
    "    adv = _advisory_lines(context)\n",
    "    if adv:\n",
    "        lines.append(\"Advisory:\")\n",
    "        lines.extend([f\"- {x}\" for x in adv])\n",
    "\n",
    "    lines.append(f\"Generated at (SG): {context.get('timestamp_sg', now_sg().isoformat(timespec='seconds'))}\")\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "\n",
    "def _refine_with_groq_if_enabled(state: AgentState, deterministic_text: str) -> tuple[str, str]:\n",
    "    if not USE_GROQ_SYNTHESIS:\n",
    "        return deterministic_text, \"rules-only\"\n",
    "\n",
    "    payload = {\n",
    "        \"query\": state.get(\"user_query\"),\n",
    "        \"intent\": state.get(\"intent\"),\n",
    "        \"entities\": state.get(\"entities\"),\n",
    "        \"context\": state.get(\"context\"),\n",
    "        \"tool_result\": state.get(\"tool_result\"),\n",
    "        \"deterministic_draft\": deterministic_text,\n",
    "    }\n",
    "    prompt = (\n",
    "        \"You are a precise Singapore public transport assistant. Use only grounded JSON. \"\n",
    "        \"Do not invent data. Keep answer concise (max 120 words).\\n\\n\"\n",
    "        f\"Grounded JSON:\\n{json.dumps(payload, ensure_ascii=True)}\"\n",
    "    )\n",
    "\n",
    "    text, err = call_groq_chat(prompt)\n",
    "    if text:\n",
    "        return text, f\"groq:{GROQ_MODEL}\"\n",
    "    if SHOW_LLM_ERRORS and err:\n",
    "        return deterministic_text + f\"\\n[Groq fallback reason: {err}]\", \"rules-fallback\"\n",
    "    return deterministic_text, \"rules-fallback\"\n",
    "\n",
    "def compose_response(state: AgentState) -> AgentState:\n",
    "    draft = _build_deterministic_response(state)\n",
    "    final_text, model_used = _refine_with_groq_if_enabled(state, draft)\n",
    "    state[\"response\"] = final_text\n",
    "    state[\"model_used\"] = model_used\n",
    "    state.setdefault(\"steps\", []).append(\"compose_response\")\n",
    "    return state\n",
    "\n",
    "\n",
    "try:\n",
    "    from langgraph.graph import END, StateGraph\n",
    "\n",
    "    graph = StateGraph(AgentState)\n",
    "    graph.add_node(\"parse_query\", parse_query)\n",
    "    graph.add_node(\"enrich_context\", enrich_context)\n",
    "    graph.add_node(\"run_transport_tool\", run_transport_tool)\n",
    "    graph.add_node(\"compose_response\", compose_response)\n",
    "\n",
    "    graph.set_entry_point(\"parse_query\")\n",
    "    graph.add_edge(\"parse_query\", \"enrich_context\")\n",
    "    graph.add_edge(\"enrich_context\", \"run_transport_tool\")\n",
    "    graph.add_edge(\"run_transport_tool\", \"compose_response\")\n",
    "    graph.add_edge(\"compose_response\", END)\n",
    "\n",
    "    compiled_agent = graph.compile()\n",
    "\n",
    "    def run_agent(user_query: str) -> AgentState:\n",
    "        return compiled_agent.invoke({\"user_query\": user_query, \"steps\": []})\n",
    "\n",
    "    runner_mode = \"langgraph\"\n",
    "\n",
    "except Exception as graph_exc:\n",
    "\n",
    "    def run_agent(user_query: str) -> AgentState:\n",
    "        s: AgentState = {\"user_query\": user_query, \"steps\": []}\n",
    "        s = parse_query(s)\n",
    "        s = enrich_context(s)\n",
    "        s = run_transport_tool(s)\n",
    "        s = compose_response(s)\n",
    "        return s\n",
    "\n",
    "    runner_mode = f\"fallback ({graph_exc})\"\n",
    "\n",
    "print(\"Agent runner mode:\", runner_mode)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1116e0",
   "metadata": {},
   "source": [
    "## Part 1 - Functional Demo\n",
    "\n",
    "Single query to verify end-to-end workflow behavior.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d554947e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User query: When is the next bus at stop 01013?\n",
      "\n",
      "Agent response:\n",
      "Bus arrival update for stop 01013:\n",
      "Data source: lta\n",
      "No live arrivals now. This may be due to late-night service gaps at this stop.\n",
      "Fallback option: around 500 taxis are available in the latest snapshot.\n",
      "Advisory:\n",
      "- Live traffic incidents detected: expect mild schedule variability.\n",
      "\n",
      "Model used: groq:llama-3.1-8b-instant\n",
      "Executed steps: ['parse_query', 'enrich_context', 'run_transport_tool', 'compose_response']\n"
     ]
    }
   ],
   "source": [
    "sample_query = \"When is the next bus at stop 01013?\"\n",
    "sample_result = run_agent(sample_query)\n",
    "\n",
    "print(\"User query:\", sample_query)\n",
    "print()\n",
    "print(\"Agent response:\")\n",
    "print(sample_result[\"response\"])\n",
    "print()\n",
    "print(\"Model used:\", sample_result.get(\"model_used\"))\n",
    "print(\"Executed steps:\", sample_result.get(\"steps\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c91234f",
   "metadata": {},
   "source": [
    "## Part 2 - Multi-User Simulation (10 Requests)\n",
    "\n",
    "Inputs intentionally vary constraints across:\n",
    "- weather\n",
    "- traffic\n",
    "- peak/off-peak timing\n",
    "- public holiday context\n",
    "- special-event context\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3a357fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>table.sim-results {width: 100%; border-collapse: collapse; table-layout: fixed; font-family: -apple-system, BlinkMacSystemFont, Segoe UI, sans-serif;}.sim-results th, .sim-results td {border: 1px solid #d9d9d9; padding: 8px; vertical-align: top; text-align: left;}.sim-results th {background: #f3f6fa; font-weight: 600;}.sim-results tr:nth-child(even) {background: #fbfcfe;}.sim-results .col-id {width: 7%;}.sim-results .col-model {width: 16%;}.sim-results .col-cons {width: 13%;}.sim-results .col-query {width: 24%;}.sim-results .col-resp {width: 40%; line-height: 1.35;}.sim-results .response {white-space: pre-wrap; overflow-wrap: anywhere; word-break: break-word;}</style><table class='sim-results'><tr><th class='col-id'>User</th><th class='col-model'>Model</th><th class='col-cons'>Constraints</th><th class='col-query'>Query</th><th class='col-resp'>Response</th></tr><tr><td>U01</td><td>groq:llama-3.1-8b-instant</td><td>time_of_day, traffic</td><td>When is the next bus at stop 01013?</td><td class='response'>Bus Arrival Update for Stop 01013:\n",
       "\n",
       "- Data source: LTA\n",
       "- No live arrivals now. This may be due to late-night service gaps at this stop.\n",
       "- Fallback option: around 500 taxis are available in the latest snapshot.\n",
       "- Advisory:\n",
       "  - Live traffic incidents detected: expect mild schedule variability.\n",
       "\n",
       "Generated at (SG): 2026-02-23T04:22:28+08:00</td></tr><tr><td>U02</td><td>groq:llama-3.1-8b-instant</td><td>weather, traffic</td><td>I&#x27;m at Hotel Grand Pacific (Stop 01012). Is it raining? Should I take the bus?</td><td class='response'>It is not raining at your location. The current temperature is 23.9°C. \n",
       "\n",
       "Bus arrival information is not available at this time.</td></tr><tr><td>U03</td><td>groq:llama-3.1-8b-instant</td><td>accessibility</td><td>Any wheelchair accessible buses at 01019?</td><td class='response'>Bus arrival update for stop 01019:\n",
       "Data source: lta\n",
       "No live arrivals now. This may be due to late-night service gaps at this stop.\n",
       "Fallback option: around 500 taxis are available in the latest snapshot.\n",
       "Advisory:\n",
       "- Live traffic incidents detected: expect mild schedule variability.\n",
       "\n",
       "No wheelchair accessible buses available at 01019.</td></tr><tr><td>U04</td><td>groq:llama-3.1-8b-instant</td><td>holiday, time_of_day</td><td>Is it a public holiday today? Will bus frequency be affected?</td><td class='response'>No, it is not a public holiday today. Bus frequency will not be affected.</td></tr><tr><td>U05</td><td>groq:llama-3.1-8b-instant</td><td>weather</td><td>I hate rain. Check the weather before checking bus 12 at stop 01029.</td><td class='response'>The current weather is:\n",
       "\n",
       "- Temperature: 23.9°C\n",
       "- Rainfall: 0.0 mm\n",
       "- Precipitation probability: 0%\n",
       "\n",
       "There are no live bus arrivals at stop 01029.</td></tr><tr><td>U06</td><td>groq:llama-3.1-8b-instant</td><td>weather, traffic</td><td>Hello! Plan my commute now.</td><td class='response'>Your commute is planned. Current weather is 23.9°C with 0% rain probability. There are 16 traffic incidents, including road works on SLE and AYE. Taxi count is 500. Expect mild schedule variability due to traffic incidents. Your journey will be updated accordingly.</td></tr><tr><td>U07</td><td>groq:llama-3.1-8b-instant</td><td>crowding</td><td>What is the load like for buses at stop 01019?</td><td class='response'>Bus arrival update for stop 01019: \n",
       "Data source: lta\n",
       "No live arrivals now. This may be due to late-night service gaps at this stop.\n",
       "Fallback option: around 500 taxis are available in the latest snapshot.\n",
       "Advisory:\n",
       "- Live traffic incidents detected: expect mild schedule variability.</td></tr><tr><td>U08</td><td>groq:llama-3.1-8b-instant</td><td>comfort, luggage</td><td>I am carrying heavy luggage. Any non-crowded buses at 01012?</td><td class='response'>**Bus Arrival Update for Stop 01012**\n",
       "\n",
       "Data source: LTA\n",
       "No live arrivals now. This may be due to late-night service gaps at this stop.\n",
       "Fallback option: around 500 taxis are available in the latest snapshot.\n",
       "Advisory:\n",
       "- Live traffic incidents detected: expect mild schedule variability.\n",
       "\n",
       "**Traffic Snapshot**\n",
       "- Incident count: 16\n",
       "- Top incident: Road Works on SLE (towards BKE) at Woodlands Ave 2 Exit.</td></tr><tr><td>U09</td><td>groq:llama-3.1-8b-instant</td><td>holiday, bus_arrival</td><td>Check if it&#x27;s a holiday and tell me the bus times for 01029.</td><td class='response'>It&#x27;s not a public holiday. \n",
       "\n",
       "Bus times for 01029:\n",
       "No live arrivals now. This may be due to late-night service gaps at this stop.\n",
       "Fallback option: around 500 taxis are available in the latest snapshot.\n",
       "Advisory:\n",
       "- Live traffic incidents detected: expect mild schedule variability.</td></tr><tr><td>U10</td><td>groq:llama-3.1-8b-instant</td><td>invalid_stop</td><td>Bus stop 99999 please.</td><td class='response'>Bus stop 99999 is not served by any bus services. \n",
       "Data source: LTA\n",
       "No live arrivals now. This may be due to late-night service gaps at this stop.\n",
       "Fallback option: around 500 taxis are available in the latest snapshot.\n",
       "Advisory: \n",
       "- Live traffic incidents detected: expect mild schedule variability.</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Model usage distribution:** `groq:llama-3.1-8b-instant` = 10"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "simulated_users = [\n",
    "    {\"user_id\": \"U01\", \"constraints\": \"time_of_day, traffic\", \"query\": \"When is the next bus at stop 01013?\"},\n",
    "    {\"user_id\": \"U02\", \"constraints\": \"weather, traffic\", \"query\": \"I'm at Hotel Grand Pacific (Stop 01012). Is it raining? Should I take the bus?\"},\n",
    "    {\"user_id\": \"U03\", \"constraints\": \"accessibility\", \"query\": \"Any wheelchair accessible buses at 01019?\"},\n",
    "    {\"user_id\": \"U04\", \"constraints\": \"holiday, time_of_day\", \"query\": \"Is it a public holiday today? Will bus frequency be affected?\"},\n",
    "    {\"user_id\": \"U05\", \"constraints\": \"weather\", \"query\": \"I hate rain. Check the weather before checking bus 12 at stop 01029.\"},\n",
    "    {\"user_id\": \"U06\", \"constraints\": \"weather, traffic\", \"query\": \"Hello! Plan my commute now.\"},\n",
    "    {\"user_id\": \"U07\", \"constraints\": \"crowding\", \"query\": \"What is the load like for buses at stop 01019?\"},\n",
    "    {\"user_id\": \"U08\", \"constraints\": \"comfort, luggage\", \"query\": \"I am carrying heavy luggage. Any non-crowded buses at 01012?\"},\n",
    "    {\"user_id\": \"U09\", \"constraints\": \"holiday, bus_arrival\", \"query\": \"Check if it's a holiday and tell me the bus times for 01029.\"},\n",
    "    {\"user_id\": \"U10\", \"constraints\": \"invalid_stop\", \"query\": \"Bus stop 99999 please.\"},\n",
    "]\n",
    "\n",
    "RUN_SIMULATION_WITH_GROQ = True\n",
    "\n",
    "results: list[dict[str, str]] = []\n",
    "original_use_groq = USE_GROQ_SYNTHESIS\n",
    "original_budget = GROQ_CALL_BUDGET\n",
    "original_count = GROQ_CALL_COUNT\n",
    "\n",
    "if RUN_SIMULATION_WITH_GROQ and GROQ_API_KEY:\n",
    "    USE_GROQ_SYNTHESIS = True\n",
    "    if GROQ_CALL_BUDGET >= 0:\n",
    "        GROQ_CALL_BUDGET = max(GROQ_CALL_BUDGET, len(simulated_users) + 2)\n",
    "    GROQ_CALL_COUNT = 0\n",
    "else:\n",
    "    USE_GROQ_SYNTHESIS = False\n",
    "    if RUN_SIMULATION_WITH_GROQ and not GROQ_API_KEY:\n",
    "        print(\"Groq key missing. Running simulation in rules-only mode.\")\n",
    "\n",
    "for item in simulated_users:\n",
    "    agent_out = run_agent(item[\"query\"])\n",
    "    results.append(\n",
    "        {\n",
    "            \"user_id\": item[\"user_id\"],\n",
    "            \"constraints\": item[\"constraints\"],\n",
    "            \"query\": item[\"query\"],\n",
    "            \"model\": str(agent_out.get(\"model_used\", \"unknown\")),\n",
    "            \"response\": str(agent_out.get(\"response\", \"\")),\n",
    "        }\n",
    "    )\n",
    "\n",
    "USE_GROQ_SYNTHESIS = original_use_groq\n",
    "GROQ_CALL_BUDGET = original_budget\n",
    "GROQ_CALL_COUNT = original_count\n",
    "\n",
    "\n",
    "def _clean_response_text(raw: str) -> str:\n",
    "    t = (raw or \"\").strip()\n",
    "\n",
    "    # Remove fenced blocks like ```json ... ```\n",
    "    if t.startswith(\"```\"):\n",
    "        t = re.sub(r\"^```(?:json)?\\s*\", \"\", t, flags=re.IGNORECASE)\n",
    "        t = re.sub(r\"\\s*```$\", \"\", t, flags=re.MULTILINE).strip()\n",
    "\n",
    "    # If response is JSON-like, flatten it to readable lines\n",
    "    try:\n",
    "        obj = json.loads(t)\n",
    "        if isinstance(obj, dict):\n",
    "            payload = obj.get(\"response\", obj)\n",
    "\n",
    "            if isinstance(payload, str):\n",
    "                return payload.strip()\n",
    "\n",
    "            if isinstance(payload, dict):\n",
    "                lines: list[str] = []\n",
    "                if payload.get(\"summary\"):\n",
    "                    lines.append(str(payload[\"summary\"]))\n",
    "                if payload.get(\"advisory\"):\n",
    "                    lines.append(f\"Advisory: {payload['advisory']}\")\n",
    "\n",
    "                w = payload.get(\"weather\")\n",
    "                if isinstance(w, dict):\n",
    "                    temp = w.get(\"temperature\", w.get(\"temperature_c\", \"N/A\"))\n",
    "                    rain_prob = w.get(\"rain_probability\", w.get(\"precip_probability\", \"N/A\"))\n",
    "                    lines.append(f\"Weather: {temp}C | Rain prob: {rain_prob}%\")\n",
    "\n",
    "                tr = payload.get(\"traffic\")\n",
    "                if isinstance(tr, dict):\n",
    "                    lines.append(f\"Traffic incidents: {tr.get('incidents', tr.get('incident_count', 'N/A'))}\")\n",
    "\n",
    "                tx = payload.get(\"taxi\")\n",
    "                if isinstance(tx, dict):\n",
    "                    lines.append(f\"Taxi available: {tx.get('count', tx.get('taxi_count', 'N/A'))}\")\n",
    "\n",
    "                if lines:\n",
    "                    return \"\\n\".join(lines)\n",
    "\n",
    "        if isinstance(obj, list):\n",
    "            return json.dumps(obj, ensure_ascii=False)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    return t\n",
    "\n",
    "\n",
    "def render_results_table(rows: list[dict[str, str]]) -> None:\n",
    "    if HTML is None:\n",
    "        for r in rows:\n",
    "            print(f\"{r['user_id']} | {r['model']} | {r['constraints']} | {r['query']} | {_clean_response_text(r['response'])}\")\n",
    "        return\n",
    "\n",
    "    style = (\n",
    "        \"<style>\"\n",
    "        \"table.sim-results {width: 100%; border-collapse: collapse; table-layout: fixed; \"\n",
    "        \"font-family: -apple-system, BlinkMacSystemFont, Segoe UI, sans-serif;}\"\n",
    "        \".sim-results th, .sim-results td {border: 1px solid #d9d9d9; padding: 8px; vertical-align: top; text-align: left;}\"\n",
    "        \".sim-results th {background: #f3f6fa; font-weight: 600;}\"\n",
    "        \".sim-results tr:nth-child(even) {background: #fbfcfe;}\"\n",
    "        \".sim-results .col-id {width: 7%;}\"\n",
    "        \".sim-results .col-model {width: 16%;}\"\n",
    "        \".sim-results .col-cons {width: 13%;}\"\n",
    "        \".sim-results .col-query {width: 24%;}\"\n",
    "        \".sim-results .col-resp {width: 40%; line-height: 1.35;}\"\n",
    "        \".sim-results .response {white-space: pre-wrap; overflow-wrap: anywhere; word-break: break-word;}\"\n",
    "        \"</style>\"\n",
    "    )\n",
    "\n",
    "    header = (\n",
    "        \"<tr>\"\n",
    "        \"<th class='col-id'>User</th>\"\n",
    "        \"<th class='col-model'>Model</th>\"\n",
    "        \"<th class='col-cons'>Constraints</th>\"\n",
    "        \"<th class='col-query'>Query</th>\"\n",
    "        \"<th class='col-resp'>Response</th>\"\n",
    "        \"</tr>\"\n",
    "    )\n",
    "\n",
    "    body_rows = []\n",
    "    for r in rows:\n",
    "        resp = _clean_response_text(r[\"response\"])\n",
    "        body_rows.append(\n",
    "            \"<tr>\"\n",
    "            f\"<td>{escape(r['user_id'])}</td>\"\n",
    "            f\"<td>{escape(r['model'])}</td>\"\n",
    "            f\"<td>{escape(r['constraints'])}</td>\"\n",
    "            f\"<td>{escape(r['query'])}</td>\"\n",
    "            f\"<td class='response'>{escape(resp)}</td>\"\n",
    "            \"</tr>\"\n",
    "        )\n",
    "\n",
    "    html = style + \"<table class='sim-results'>\" + header + \"\".join(body_rows) + \"</table>\"\n",
    "    display(HTML(html))\n",
    "\n",
    "\n",
    "model_counts: dict[str, int] = {}\n",
    "for r in results:\n",
    "    model_counts[r[\"model\"]] = model_counts.get(r[\"model\"], 0) + 1\n",
    "\n",
    "render_results_table(results)\n",
    "\n",
    "summary = \", \".join(f\"`{k}` = {v}\" for k, v in model_counts.items())\n",
    "if Markdown is not None:\n",
    "    display(Markdown(\"**Model usage distribution:** \" + summary))\n",
    "else:\n",
    "    print(\"Model usage distribution:\", summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a2414f",
   "metadata": {},
   "source": [
    "## Design Decisions and Assumptions\n",
    "\n",
    "- Tool-driven orchestration is used for response grounding.\n",
    "- LLM is optional and only applied as a response-polish layer.\n",
    "- Bus stop queries assume a valid 5-digit Singapore stop code.\n",
    "- Event handling is keyword-based in this take-home version.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fac70fe",
   "metadata": {},
   "source": [
    "## Deployment Considerations (Real-World)\n",
    "\n",
    "1. Serve the graph behind FastAPI.\n",
    "2. Add Redis cache for high-frequency snapshot data.\n",
    "3. Use async HTTP + circuit breakers for upstream reliability.\n",
    "4. Add observability (node latency, fallback rate, API error rate).\n",
    "5. Store keys in a secret manager and enforce rotation.\n",
    "6. Add CI tests with fixed payload fixtures.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
